apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "tsd-ml-api.fullname" . }}
  labels:
    app.kubernetes.io/name: {{ include "tsd-ml-api.name" . }}
    helm.sh/chart: {{ include "tsd-ml-api.chart" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app.kubernetes.io/name: {{ include "tsd-ml-api.name" . }}
      app.kubernetes.io/instance: {{ .Release.Name }}
  template:
    metadata:
      labels:
        app.kubernetes.io/name: {{ include "tsd-ml-api.name" . }}
        app.kubernetes.io/instance: {{ .Release.Name }}
    spec:
      containers:
        - name: {{ .Chart.Name }}-ml-api
          image: "{{ .Values.image.ml_api.repository }}:{{ .Values.image.ml_api.tag }}"
          imagePullPolicy: {{ .Values.image.ml_api.pullPolicy }}
          env:
            - name: "DEBUG"
              value: "True"
            - name: "FLASK_APP"
              value: "server.py"
            {{- if .Values.ml_api.gpu.enabled }}
            - name: "HAS_GPU"
              value: "True"
            {{- end }}
          command:
            - sh
            - -c
            - python server.py
          ports:
            - name: http
              containerPort: 3333
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /p/
              port: 3333
          readinessProbe:
            httpGet:
              path: /p/
              port: 3333
          resources:
            {{- if .Values.ml_api.gpu.enabled }}
            limits:
              nvidia.com/gpu: {{ .Values.ml_api.gpu.gpus_per_pod }}
            {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
    {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
    {{- end }}
    {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
    {{- end }}
